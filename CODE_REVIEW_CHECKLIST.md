# Code Compass 代码审查清单

## 审查目标

请帮我审查Code Compass项目的Day 1-5的实现，重点关注：
1. **架构设计的合理性** - 是否符合第一性原理
2. **代码质量** - 是否有明显的bug或设计缺陷
3. **性能考虑** - 缓存机制是否真的能提升性能
4. **可扩展性** - 是否容易添加新语言支持

---

## 📋 审查清单

### 1. 数据结构设计 (`models.py`)

**关键问题**：
- [ ] `Symbol`、`FileInfo`、`RepoMap` 的数据结构是否合理？
- [ ] 是否有冗余字段？
- [ ] 是否缺少必要字段？
- [ ] `to_map_line()` 和 `to_text()` 的输出格式是否符合Aider的风格？

**需要特别关注**：
- 我们只存储签名，不存储函数体 - 这个设计对吗？
- `parent` 字段用于方法的类名 - 这样设计够用吗？

---

### 2. Python解析器 (`parsers/python_parser.py`)

**关键问题**：
- [ ] AST遍历逻辑是否正确？
- [ ] 是否会漏掉某些符号（如嵌套类、lambda等）？
- [ ] 类型注解提取是否完整（泛型、Union、Optional等）？
- [ ] 装饰器提取是否正确？
- [ ] Import提取是否完整（相对导入、from import等）？

**需要特别关注**：
- `_get_name()` 方法处理复杂类型注解的逻辑 - 是否会崩溃？
- 语法错误处理 - 是否会导致整个索引失败？
- 我们没有提取lambda、嵌套函数 - 这是否是问题？

**已知限制**：
- 不支持嵌套类和嵌套函数
- 不支持lambda表达式
- 不支持类型别名（TypeAlias）

---

### 3. 依赖图 (`graph.py`)

**关键问题**：
- [ ] PageRank算法实现是否正确？
- [ ] 依赖关系解析是否准确？
- [ ] `_resolve_import()` 方法能否处理大部分场景？

**需要特别关注**：
- 相对导入解析 - 逻辑是否正确？
- 标准库和第三方库的过滤 - 是否会误判？
- PageRank迭代10次 - 是否足够收敛？

**已知限制**：
- 无法处理动态导入（`importlib`、`__import__`）
- 无法处理复杂的包结构（如`__init__.py`的re-export）
- 相对导入解析是简化版本，可能不准确

---

### 4. 缓存层 (`cache.py`)

**关键问题**：
- [ ] 数据库schema设计是否合理？
- [ ] 索引是否足够（会不会慢查询）？
- [ ] 增量更新逻辑是否正确？
- [ ] 是否有SQL注入风险？
- [ ] 是否有并发问题（多进程同时写入）？

**需要特别关注**：
- `save_file()` 的更新逻辑 - 是否会产生孤儿记录？
- 外键级联删除 - 是否会误删数据？
- `is_file_cached()` 的哈希对比 - 是否足够可靠？

**已知限制**：
- 没有并发控制（不支持多进程同时索引）
- 没有全文搜索（FTS5）支持
- 没有数据库迁移机制

---

### 5. 整体架构

**关键问题**：
- [ ] 模块之间的依赖关系是否清晰？
- [ ] 是否有循环依赖？
- [ ] 是否符合单一职责原则？
- [ ] 是否容易测试？

**需要特别关注**：
- `models.py` 是否应该包含业务逻辑（`to_map_line()`等）？
- `graph.py` 和 `cache.py` 的职责划分是否清晰？

---

## 🎯 核心设计决策审查

### 决策1: 只提取签名，不提取函数体

**理由**：减少token消耗，AI只需要知道API表面

**请审查**：
- 这个假设对吗？AI是否真的不需要函数体？
- 对于调试场景，是否需要部分函数体？

### 决策2: 使用SQLite而非内存缓存

**理由**：持久化，支持增量更新

**请审查**：
- SQLite的性能是否足够？
- 是否应该考虑其他存储方案（如pickle、JSON）？

### 决策3: 使用PageRank计算文件重要性

**理由**：被引用多的文件更重要

**请审查**：
- 这个假设对吗？
- 是否有更好的重要性度量方式？
- 对于没有依赖关系的文件（如脚本），如何处理？

### 决策4: 不支持动态语言特性（反射、动态导入）

**理由**：静态分析无法100%准确

**请审查**：
- 这个限制是否可接受？
- 是否应该在文档中明确说明？
- 是否有部分解决方案？

---

## 🐛 已知Bug和待改进点

1. **相对导入解析不准确** - `graph.py` 的 `_resolve_import()` 是简化版本
2. **没有嵌套符号支持** - 嵌套类、嵌套函数会被忽略
3. **没有并发控制** - 多进程同时索引会冲突
4. **没有错误恢复** - 如果某个文件解析失败，会打印警告但继续

---

## 📊 测试覆盖率

### Python解析器测试 (`test_python_parser.py`)
- ✅ 简单函数
- ✅ 类和方法
- ✅ 装饰器
- ✅ 语法错误处理
- ✅ Import提取
- ✅ 继承关系
- ✅ 复杂类型注解
- ✅ Async函数

### 缓存层测试 (`test_cache.py`)
- ✅ 数据库初始化
- ✅ 保存和检索
- ✅ 哈希检查
- ✅ 更新已存在文件
- ✅ 符号查找
- ✅ 模糊搜索
- ✅ 统计信息
- ✅ 删除操作
- ✅ 清空缓存

**未测试的场景**：
- 大型项目（1000+文件）的性能
- 并发写入
- 数据库损坏恢复
- 边界情况（超长文件名、特殊字符等）

---

## 🔍 建议的审查方式

### 方式1: 逐文件审查

```bash
# 按顺序审查每个文件
1. models.py - 数据结构
2. graph.py - 依赖图
3. parsers/python_parser.py - 解析器
4. cache.py - 缓存层
```

### 方式2: 按功能审查

```bash
# 按功能链路审查
1. 解析流程: python_parser.py -> models.py
2. 缓存流程: cache.py -> models.py
3. 依赖分析: graph.py -> models.py
```

### 方式3: 运行测试并分析

```bash
# 运行所有测试
cd ~/code-compass
python3 tests/test_python_parser.py
python3 tests/test_cache.py

# 查看测试覆盖的场景
```

---

## ❓ 需要Gemini回答的关键问题

1. **架构层面**：这个三层架构（解析器 -> 缓存 -> 依赖图）是否合理？有没有更好的设计？

2. **性能层面**：SQLite缓存真的能提升性能吗？还是会成为瓶颈？

3. **准确性层面**：静态分析的局限性（无法处理反射、动态导入）是否会导致生成的map不可用？

4. **竞争力层面**：相比Aider的repomap，我们的优势（缓存）是否真的有价值？

5. **可扩展性层面**：如果要添加JavaScript/TypeScript支持，当前架构是否需要大改？

---

## 📝 审查后请提供

1. **严重问题清单** - 必须修复的bug或设计缺陷
2. **改进建议** - 可以优化的地方
3. **风险评估** - 这个项目能否达到预期目标
4. **下一步建议** - 是继续Day 6-7，还是先重构Day 1-5

---

**审查人**: Gemini / 其他AI助手  
**审查日期**: 2026-01-30  
**代码版本**: Day 1-5 (MVP前半部分)
